{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3cbe4cf",
   "metadata": {},
   "source": [
    "# Hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f93220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hotspots returned: 52541\n",
      "\n",
      "Sample hotspot:\n",
      "{'locId': 'L10913808', 'locName': '\"The Maze\" Trail', 'countryCode': 'US', 'subnational1Code': 'US-UT', 'subnational2Code': 'US-UT-053', 'lat': 37.294524, 'lng': -113.692871, 'latestObsDt': '2025-11-15 14:02', 'numSpeciesAllTime': 20}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Your API key\n",
    "api_key = \"3g5voge8rcai\"\n",
    "\n",
    "# Region code for the entire United States\n",
    "region_code = \"US\"\n",
    "\n",
    "# API endpoint\n",
    "url = f\"https://api.ebird.org/v2/ref/hotspot/{region_code}\"\n",
    "\n",
    "# Query parameters\n",
    "params = {\n",
    "    \"back\": 30,   # last 30 days (max allowed)\n",
    "    \"fmt\": \"json\" # return JSON format\n",
    "}\n",
    "\n",
    "# Headers including your API key\n",
    "headers = {\n",
    "    \"X-eBirdApiToken\": api_key\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    hotspots = response.json()\n",
    "    print(f\"Number of hotspots returned: {len(hotspots)}\\n\")\n",
    "    print(\"Sample hotspot:\")\n",
    "    print(hotspots[0])  # print first hotspot entry\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53dc996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved as us_hotspots_last30days.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert JSON list to DataFrame\n",
    "df = pd.DataFrame(hotspots)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"us_hotspots_last30days.csv\", index=False)\n",
    "\n",
    "print(\"CSV saved as us_hotspots_last30days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f0a859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  hotspot_count  species_richness\n",
      "0    AK            404               325\n",
      "1    AL            368               343\n",
      "2    AR            407               301\n",
      "3    AZ           1231               339\n",
      "4    CA           6669               445\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "\n",
    "base_dir = \"/Users/xingyechen/Downloads/DataEngineering_FinalProject/map\"\n",
    "\n",
    "hotspot_file = os.path.join(base_dir, \"us_hotspots_last30days.csv\")\n",
    "df_hot = pd.read_csv(hotspot_file)\n",
    "\n",
    "# Extract state code (US-CA → CA)\n",
    "df_hot[\"state\"] = df_hot[\"subnational1Code\"].str.split(\"-\").str[1]\n",
    "\n",
    "# === OPTION A: HOTSPOT COUNT PER STATE ===\n",
    "hotspot_count = df_hot.groupby(\"state\").size().reset_index(name=\"hotspot_count\")\n",
    "\n",
    "# === OPTION B: SPECIES RICHNESS PER STATE (use max species per hotspot in that state) ===\n",
    "species_richness = df_hot.groupby(\"state\")[\"numSpeciesAllTime\"].max().reset_index(name=\"species_richness\")\n",
    "\n",
    "# === MERGE TO SINGLE DATAFRAME ===\n",
    "state_stats = hotspot_count.merge(species_richness, on=\"state\")\n",
    "\n",
    "print(state_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f27fa",
   "metadata": {},
   "source": [
    "## Store into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a259091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotspots returned: 52548\n",
      "\n",
      "State Stats Preview:\n",
      "  state  hotspot_count  species_richness\n",
      "0    AK            394               325\n",
      "1    AL            373               343\n",
      "2    AR            414               301\n",
      "3    AZ           1220               339\n",
      "4    CA           6555               445\n",
      "\n",
      "Database saved → /Users/xingyechen/Downloads/DataEngineering_FinalProject/ebird_hotspots.db\n",
      "Tables created: states, hotspots, state_stats\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# === 1. Call eBird Hotspot API ===\n",
    "api_key = \"3g5voge8rcai\"\n",
    "region_code = \"US\"\n",
    "\n",
    "url = f\"https://api.ebird.org/v2/ref/hotspot/{region_code}\"\n",
    "\n",
    "params = {\"back\": 30, \"fmt\": \"json\"}\n",
    "headers = {\"X-eBirdApiToken\": api_key}\n",
    "\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"API Error {response.status_code}: {response.text}\")\n",
    "\n",
    "hotspots = response.json()\n",
    "print(\"Hotspots returned:\", len(hotspots))\n",
    "\n",
    "# === 2. Convert JSON to DataFrame ===\n",
    "df = pd.DataFrame(hotspots)\n",
    "\n",
    "# Extract 2-letter state code (US-NY → NY)\n",
    "df[\"state\"] = df[\"subnational1Code\"].str.split(\"-\").str[1]\n",
    "\n",
    "# === 3. Compute state-level stats ===\n",
    "hotspot_count = df.groupby(\"state\").size().reset_index(name=\"hotspot_count\")\n",
    "species_richness = df.groupby(\"state\")[\"numSpeciesAllTime\"].max().reset_index(name=\"species_richness\")\n",
    "\n",
    "state_stats = hotspot_count.merge(species_richness, on=\"state\")\n",
    "\n",
    "print(\"\\nState Stats Preview:\")\n",
    "print(state_stats.head())\n",
    "\n",
    "# === 4. SAVE TO NORMALIZED DATABASE ===\n",
    "\n",
    "db_path = os.path.join(os.getcwd(), \"ebird_hotspots.db\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# --- Create normalized schema ---\n",
    "cur.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS hotspots;\n",
    "DROP TABLE IF EXISTS states;\n",
    "DROP TABLE IF EXISTS state_stats;\n",
    "\n",
    "CREATE TABLE states (\n",
    "    state_code TEXT PRIMARY KEY,\n",
    "    state_name TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE hotspots (\n",
    "    hotspot_id TEXT PRIMARY KEY,\n",
    "    locName TEXT,\n",
    "    state_code TEXT,\n",
    "    county_code TEXT,\n",
    "    lat REAL,\n",
    "    lng REAL,\n",
    "    latestObsDt TEXT,\n",
    "    species_richness INTEGER,\n",
    "    FOREIGN KEY (state_code) REFERENCES states(state_code)\n",
    ");\n",
    "\n",
    "CREATE TABLE state_stats (\n",
    "    state_code TEXT PRIMARY KEY,\n",
    "    hotspot_count INTEGER,\n",
    "    species_richness INTEGER,\n",
    "    FOREIGN KEY (state_code) REFERENCES states(state_code)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# === Insert STATES table ===\n",
    "states_unique = pd.DataFrame({\"state_code\": df[\"state\"].unique()})\n",
    "states_unique[\"state_name\"] = None  # optional for now\n",
    "\n",
    "states_unique.to_sql(\"states\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "# === Insert HOTSPOTS table ===\n",
    "hotspots_table = pd.DataFrame({\n",
    "    \"hotspot_id\": df[\"locId\"],\n",
    "    \"locName\": df[\"locName\"],\n",
    "    \"state_code\": df[\"state\"],\n",
    "    \"county_code\": df[\"subnational2Code\"],\n",
    "    \"lat\": df[\"lat\"],\n",
    "    \"lng\": df[\"lng\"],\n",
    "    \"latestObsDt\": df[\"latestObsDt\"],\n",
    "    \"species_richness\": df[\"numSpeciesAllTime\"],\n",
    "})\n",
    "\n",
    "hotspots_table.to_sql(\"hotspots\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "# === Insert STATE_STATS table ===\n",
    "state_stats.rename(columns={\"state\": \"state_code\"}, inplace=True)\n",
    "state_stats.to_sql(\"state_stats\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nDatabase saved → {db_path}\")\n",
    "print(\"Tables created: states, hotspots, state_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50a3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add a log column to reduce skew\n",
    "state_stats['log_hotspot'] = np.log1p(state_stats['hotspot_count'])  # log(1 + x)\n",
    "state_stats['log_richness'] = np.log1p(state_stats['species_richness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05857ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Geo Info\n",
    "geo_path = os.path.join(base_dir, \"us-states.json\")\n",
    "with open(geo_path, \"r\") as f:\n",
    "    us_geo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873e3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>hotspot_count</th>\n",
       "      <th>species_richness</th>\n",
       "      <th>log_hotspot</th>\n",
       "      <th>log_richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>394</td>\n",
       "      <td>325</td>\n",
       "      <td>5.978886</td>\n",
       "      <td>5.786897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>373</td>\n",
       "      <td>343</td>\n",
       "      <td>5.924256</td>\n",
       "      <td>5.840642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>414</td>\n",
       "      <td>301</td>\n",
       "      <td>6.028279</td>\n",
       "      <td>5.710427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>1220</td>\n",
       "      <td>339</td>\n",
       "      <td>7.107425</td>\n",
       "      <td>5.828946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>6555</td>\n",
       "      <td>445</td>\n",
       "      <td>8.788136</td>\n",
       "      <td>6.100319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>1558</td>\n",
       "      <td>353</td>\n",
       "      <td>7.351800</td>\n",
       "      <td>5.869297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>838</td>\n",
       "      <td>327</td>\n",
       "      <td>6.732211</td>\n",
       "      <td>5.793014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DC</td>\n",
       "      <td>88</td>\n",
       "      <td>266</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>5.587249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DE</td>\n",
       "      <td>207</td>\n",
       "      <td>334</td>\n",
       "      <td>5.337538</td>\n",
       "      <td>5.814131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FL</td>\n",
       "      <td>2827</td>\n",
       "      <td>354</td>\n",
       "      <td>7.947325</td>\n",
       "      <td>5.872118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  hotspot_count  species_richness  log_hotspot  log_richness\n",
       "0         AK            394               325     5.978886      5.786897\n",
       "1         AL            373               343     5.924256      5.840642\n",
       "2         AR            414               301     6.028279      5.710427\n",
       "3         AZ           1220               339     7.107425      5.828946\n",
       "4         CA           6555               445     8.788136      6.100319\n",
       "5         CO           1558               353     7.351800      5.869297\n",
       "6         CT            838               327     6.732211      5.793014\n",
       "7         DC             88               266     4.488636      5.587249\n",
       "8         DE            207               334     5.337538      5.814131\n",
       "9         FL           2827               354     7.947325      5.872118"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d31b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping 2-letter codes to FIPS\n",
    "state_fips = {\n",
    "    'AL': '01','AK':'02','AZ':'04','AR':'05','CA':'06', \n",
    "    'CO':'08','CT':'09','DE':'10','FL':'12','GA':'13',\n",
    "    'HI':'15','ID':'16','IL':'17','IN':'18','IA':'19',\n",
    "    'KS':'20','KY':'21','LA':'22','ME':'23','MD':'24',\n",
    "    'MA':'25','MI':'26','MN':'27','MS':'28','MO':'29',\n",
    "    'MT':'30','NE':'31','NV':'32','NH':'33','NJ':'34',\n",
    "    'NM':'35','NY':'36','NC':'37','ND':'38','OH':'39',\n",
    "    'OK':'40','OR':'41','PA':'42','RI':'44','SC':'45',\n",
    "    'SD':'46','TN':'47','TX':'48','UT':'49','VT':'50',\n",
    "    'VA':'51','WA':'53','WV':'54','WI':'55','WY':'56'\n",
    "}\n",
    "\n",
    "state_stats['fips'] = state_stats['state_code'].map(state_fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b84582",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"fips\", \"log_hotspot\"]\n",
    "key_on=\"feature.id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5836293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'features'])\n",
      "{'type': 'Feature', 'id': '01', 'properties': {'name': 'Alabama', 'density': 94.65}, 'geometry': {'type': 'Polygon', 'coordinates': [[[-87.359296, 35.00118], [-85.606675, 34.984749], [-85.431413, 34.124869], [-85.184951, 32.859696], [-85.069935, 32.580372], [-84.960397, 32.421541], [-85.004212, 32.322956], [-84.889196, 32.262709], [-85.058981, 32.13674], [-85.053504, 32.01077], [-85.141136, 31.840985], [-85.042551, 31.539753], [-85.113751, 31.27686], [-85.004212, 31.003013], [-85.497137, 30.997536], [-87.600282, 30.997536], [-87.633143, 30.86609], [-87.408589, 30.674397], [-87.446927, 30.510088], [-87.37025, 30.427934], [-87.518128, 30.280057], [-87.655051, 30.247195], [-87.90699, 30.411504], [-87.934375, 30.657966], [-88.011052, 30.685351], [-88.10416, 30.499135], [-88.137022, 30.318396], [-88.394438, 30.367688], [-88.471115, 31.895754], [-88.241084, 33.796253], [-88.098683, 34.891641], [-88.202745, 34.995703], [-87.359296, 35.00118]]]}}\n"
     ]
    }
   ],
   "source": [
    "# Check the top-level keys\n",
    "print(us_geo.keys())  \n",
    "# Should show: dict_keys(['type', 'features'])\n",
    "\n",
    "# Inspect the first feature\n",
    "first_feature = us_geo['features'][0]\n",
    "print(first_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b98d82b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Map saved to: /Users/xingyechen/Downloads/DataEngineering_FinalProject/map/ebird_species_hotspot_map.html\n",
      "→ Open it in your browser. You can toggle species or state metrics.\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === CONFIG ===\n",
    "base_dir = \"/Users/xingyechen/Downloads/DataEngineering_FinalProject/map\"\n",
    "species_files = {\n",
    "    \"acowoo\": os.path.join(base_dir, \"acowoo.csv\"),\n",
    "    \"ameavo\": os.path.join(base_dir, \"ameavo.csv\"),\n",
    "    \"amhgul1\": os.path.join(base_dir, \"amhgul1.csv\"),\n",
    "    \"amwpel\": os.path.join(base_dir, \"amwpel.csv\"),\n",
    "    \"annhum\": os.path.join(base_dir, \"annhum.csv\"),\n",
    "}\n",
    "\n",
    "species_colors = {\n",
    "    \"acowoo\": \"red\",\n",
    "    \"ameavo\": \"blue\",\n",
    "    \"amhgul1\": \"green\",\n",
    "    \"amwpel\": \"orange\",\n",
    "    \"annhum\": \"purple\"\n",
    "}\n",
    "\n",
    "# Load US states GeoJSON with state codes as \"id\"\n",
    "geo_path = os.path.join(base_dir, \"us-states.json\")  # download from PublicaMundi\n",
    "with open(geo_path) as f:\n",
    "    us_geo = json.load(f)\n",
    "\n",
    "# === BASE MAP ===\n",
    "m = folium.Map(location=[39.8283, -98.5795], zoom_start=5)\n",
    "\n",
    "# === ADD SPECIES LAYERS ===\n",
    "for code, path in species_files.items():\n",
    "    fg = folium.FeatureGroup(name=f\"Species: {code}\", show=False)\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        for _, row in df.iterrows():\n",
    "            lat = row.get(\"LATITUDE\") or row.get(\"lat\")\n",
    "            lon = row.get(\"LONGITUDE\") or row.get(\"lng\")\n",
    "            if pd.isna(lat) or pd.isna(lon):\n",
    "                continue\n",
    "\n",
    "            popup = folium.Popup(\n",
    "                f\"<b>{row.get('COMMON NAME', row.get('comName', ''))}</b><br>\"\n",
    "                f\"<i>{row.get('SCIENTIFIC NAME', row.get('sciName', ''))}</i><br>\"\n",
    "                f\"Location: {row.get('LOCATION NAME', row.get('locName', ''))}<br>\"\n",
    "                f\"Count: {row.get('OBSERVATION COUNT', row.get('howMany', ''))}<br>\"\n",
    "                f\"Date: {row.get('OBSERVATION DATE', row.get('obsDt', ''))}\",\n",
    "                max_width=250\n",
    "            )\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=5,\n",
    "                color=species_colors.get(code, \"black\"),\n",
    "                fill=True,\n",
    "                fill_opacity=0.8,\n",
    "                popup=popup\n",
    "            ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "# Hotspot choropleth with log scale\n",
    "folium.Choropleth(\n",
    "    geo_data=us_geo,\n",
    "    data=state_stats,\n",
    "    columns=[\"fips\", \"log_hotspot\"],   # use the FIPS column\n",
    "    key_on=\"feature.id\",               # match GeoJSON feature id\n",
    "    fill_color=\"OrRd\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Hotspot Count (log scale)\",\n",
    "    name=\"Hotspot Count\",\n",
    "    show=False\n",
    ").add_to(m)\n",
    "\n",
    "# Species richness choropleth with log scale\n",
    "folium.Choropleth(\n",
    "    geo_data=us_geo,\n",
    "    data=state_stats,\n",
    "    columns=[\"fips\", \"log_richness\"],  # use the FIPS column\n",
    "    key_on=\"feature.id\",\n",
    "    fill_color=\"YlGnBu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Species Richness (log scale)\",\n",
    "    name=\"Species Richness\",\n",
    "    show=False\n",
    ").add_to(m)\n",
    "\n",
    "# === LAYER CONTROL ===\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# === LIMIT TO ONE SPECIES LAYER AT A TIME (JS) ===\n",
    "js = \"\"\"\n",
    "<script>\n",
    "document.addEventListener('DOMContentLoaded', function() {\n",
    "    var checkboxes = document.querySelectorAll('.leaflet-control-layers-selector[type=\"checkbox\"]');\n",
    "    checkboxes.forEach(function(cb) {\n",
    "        cb.addEventListener('change', function() {\n",
    "            if (this.nextSibling.textContent.trim().startsWith('Species:')) {\n",
    "                checkboxes.forEach(function(other) {\n",
    "                    if (other !== cb && other.checked && other.nextSibling.textContent.trim().startsWith('Species:')) {\n",
    "                        other.click();\n",
    "                    }\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "output_path = os.path.join(base_dir, \"ebird_species_hotspot_map.html\")\n",
    "m.save(output_path)\n",
    "\n",
    "# Inject JS at the end\n",
    "with open(output_path, \"a\") as f:\n",
    "    f.write(js)\n",
    "\n",
    "print(f\"✅ Map saved to: {output_path}\")\n",
    "print(\"→ Open it in your browser. You can toggle species or state metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d145ea",
   "metadata": {},
   "source": [
    "# Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5822415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: convert lat/lng to state using bounding boxes\n",
    "def latlon_to_state(lat, lon):\n",
    "    for state in us.states.STATES:\n",
    "        if state.bounding_box is None:\n",
    "            continue\n",
    "        min_lon, min_lat, max_lon, max_lat = state.bounding_box\n",
    "        if (min_lat <= lat <= max_lat) and (min_lon <= lon <= max_lon):\n",
    "            return state.abbr\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f1635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load US states polygons\n",
    "shp_path = os.path.join(base_dir, \"shapefiles\", \"cb_2022_us_state_20m.shp\")\n",
    "states_gdf = gpd.read_file(shp_path)[[\"STUSPS\", \"geometry\"]]  # STUSPS = 2-letter code\n",
    "\n",
    "def latlon_to_state(lat, lon):\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        return None\n",
    "\n",
    "    point = Point(lon, lat)  # shapely uses (x=lon, y=lat)\n",
    "\n",
    "    for _, row in states_gdf.iterrows():\n",
    "        if row[\"geometry\"].contains(point):\n",
    "            return row[\"STUSPS\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4300c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Map saved to: /Users/xingyechen/Downloads/DataEngineering_FinalProject/map/ebird_species_density.html\n",
      "→ Open it in your browser. You can toggle species or state metrics.\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import us  \n",
    "\n",
    "# === CONFIG ===\n",
    "base_dir = \"/Users/xingyechen/Downloads/DataEngineering_FinalProject/map\"\n",
    "species_files = {\n",
    "    \"acowoo\": os.path.join(base_dir, \"acowoo.csv\"),\n",
    "    \"ameavo\": os.path.join(base_dir, \"ameavo.csv\"),\n",
    "    \"amhgul1\": os.path.join(base_dir, \"amhgul1.csv\"),\n",
    "    \"amwpel\": os.path.join(base_dir, \"amwpel.csv\"),\n",
    "    \"annhum\": os.path.join(base_dir, \"annhum.csv\"),\n",
    "}\n",
    "\n",
    "species_colors = {\n",
    "    \"acowoo\": \"red\",\n",
    "    \"ameavo\": \"blue\",\n",
    "    \"amhgul1\": \"green\",\n",
    "    \"amwpel\": \"orange\",\n",
    "    \"annhum\": \"purple\"\n",
    "}\n",
    "\n",
    "# Load US states GeoJSON with state codes as \"id\"\n",
    "geo_path = os.path.join(base_dir, \"us-states.json\")  # download from PublicaMundi\n",
    "with open(geo_path) as f:\n",
    "    us_geo = json.load(f)\n",
    "\n",
    "# === BASE MAP ===\n",
    "m = folium.Map(location=[39.8283, -98.5795], zoom_start=5)\n",
    "\n",
    "# === ADD SPECIES LAYERS ===\n",
    "for code, path in species_files.items():\n",
    "    fg = folium.FeatureGroup(name=f\"Species: {code}\", show=False)\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        for _, row in df.iterrows():\n",
    "            lat = row.get(\"LATITUDE\") or row.get(\"lat\")\n",
    "            lon = row.get(\"LONGITUDE\") or row.get(\"lng\")\n",
    "            if pd.isna(lat) or pd.isna(lon):\n",
    "                continue\n",
    "\n",
    "            popup = folium.Popup(\n",
    "                f\"<b>{row.get('COMMON NAME', row.get('comName', ''))}</b><br>\"\n",
    "                f\"<i>{row.get('SCIENTIFIC NAME', row.get('sciName', ''))}</i><br>\"\n",
    "                f\"Location: {row.get('LOCATION NAME', row.get('locName', ''))}<br>\"\n",
    "                f\"Count: {row.get('OBSERVATION COUNT', row.get('howMany', ''))}<br>\"\n",
    "                f\"Date: {row.get('OBSERVATION DATE', row.get('obsDt', ''))}\",\n",
    "                max_width=250\n",
    "            )\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=5,\n",
    "                color=species_colors.get(code, \"black\"),\n",
    "                fill=True,\n",
    "                fill_opacity=0.8,\n",
    "                popup=popup\n",
    "            ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "# Hotspot choropleth with log scale\n",
    "folium.Choropleth(\n",
    "    geo_data=us_geo,\n",
    "    data=state_stats,\n",
    "    columns=[\"fips\", \"log_hotspot\"],   # use the FIPS column\n",
    "    key_on=\"feature.id\",               # match GeoJSON feature id\n",
    "    fill_color=\"OrRd\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Hotspot Count (log scale)\",\n",
    "    name=\"Hotspot Count\",\n",
    "    show=False\n",
    ").add_to(m)\n",
    "\n",
    "# Species richness choropleth with log scale\n",
    "folium.Choropleth(\n",
    "    geo_data=us_geo,\n",
    "    data=state_stats,\n",
    "    columns=[\"fips\", \"log_richness\"],  # use the FIPS column\n",
    "    key_on=\"feature.id\",\n",
    "    fill_color=\"YlGnBu\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Species Richness (log scale)\",\n",
    "    name=\"Species Richness\",\n",
    "    show=False\n",
    ").add_to(m)\n",
    "\n",
    "# === SPECIES DENSITY LAYERS ===\n",
    "for code, path in species_files.items():\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Find lat/lon columns\n",
    "    lat = df.get(\"LATITUDE\", df.get(\"lat\"))\n",
    "    lon = df.get(\"LONGITUDE\", df.get(\"lng\"))\n",
    "\n",
    "    df[\"state\"] = df.apply(\n",
    "        lambda r: latlon_to_state(\n",
    "            r.get(\"LATITUDE\") or r.get(\"lat\"),\n",
    "            r.get(\"LONGITUDE\") or r.get(\"lng\")\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df = df.dropna(subset=[\"state\"])\n",
    "\n",
    "    # Count observations per state\n",
    "    density = df.groupby(\"state\").size().reset_index(name=\"density\")\n",
    "\n",
    "    # Map to FIPS codes\n",
    "    density[\"fips\"] = density[\"state\"].map(state_fips)\n",
    "\n",
    "    # Add choropleth\n",
    "    folium.Choropleth(\n",
    "        geo_data=us_geo,\n",
    "        data=density,\n",
    "        columns=[\"fips\", \"density\"],\n",
    "        key_on=\"feature.id\",\n",
    "        fill_color=\"PuBuGn\",\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name=f\"{code} Density (observations per state)\",\n",
    "        name=f\"Species Density: {code}\",\n",
    "        show=False\n",
    "    ).add_to(m)\n",
    "\n",
    "# === LAYER CONTROL ===\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# === LIMIT TO ONE SPECIES LAYER AT A TIME (JS) ===\n",
    "js = \"\"\"\n",
    "<script>\n",
    "document.addEventListener('DOMContentLoaded', function() {\n",
    "    var checkboxes = document.querySelectorAll('.leaflet-control-layers-selector[type=\"checkbox\"]');\n",
    "    checkboxes.forEach(function(cb) {\n",
    "        cb.addEventListener('change', function() {\n",
    "            if (this.nextSibling.textContent.trim().startsWith('Species:')) {\n",
    "                checkboxes.forEach(function(other) {\n",
    "                    if (other !== cb && other.checked && other.nextSibling.textContent.trim().startsWith('Species:')) {\n",
    "                        other.click();\n",
    "                    }\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "output_path = os.path.join(base_dir, \"ebird_species_density.html\")\n",
    "m.save(output_path)\n",
    "\n",
    "# Inject JS at the end\n",
    "with open(output_path, \"a\") as f:\n",
    "    f.write(js)\n",
    "\n",
    "print(f\"✅ Map saved to: {output_path}\")\n",
    "print(\"→ Open it in your browser. You can toggle species or state metrics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
